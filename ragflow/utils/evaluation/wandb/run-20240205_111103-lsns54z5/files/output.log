wandb: Streaming LlamaIndex events to W&B at https://wandb.ai/arunk777/gemini-test/runs/lsns54z5
wandb: `WandbCallbackHandler` is currently in beta.
wandb: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.
[nltk_data] Downloading package punkt to /Users/asanthan/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /Users/asanthan/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
Parsing nodes: 100%|██████████| 1/1 [00:00<00:00, 38.32it/s]


100%|██████████| 8/8 [00:10<00:00,  1.25s/it]
100%|██████████| 2/2 [00:02<00:00,  1.40s/it]

100%|██████████| 2/2 [00:03<00:00,  1.50s/it]
100%|██████████| 2/2 [00:02<00:00,  1.34s/it]

100%|██████████| 2/2 [00:03<00:00,  1.83s/it]

100%|██████████| 2/2 [00:05<00:00,  2.61s/it]

100%|██████████| 2/2 [00:02<00:00,  1.44s/it]
100%|██████████| 2/2 [00:02<00:00,  1.25s/it]


100%|██████████| 2/2 [00:05<00:00,  2.62s/it]
What is the maximum number of axes that can be supported by a single Power Interface Module (PIM) in the ArmorKinetix system?
Traceback (most recent call last):
  File "/Users/asanthan/work/development/greenfield/demos/generative-ai/RAG/utils/evaluation/rag_evaluation.py", line 127, in <module>
    loop = asyncio.run(batch())
  File "/Users/asanthan/.pyenv/versions/3.10.10/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/Users/asanthan/.pyenv/versions/3.10.10/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/Users/asanthan/work/development/greenfield/demos/generative-ai/RAG/utils/evaluation/rag_evaluation.py", line 109, in batch
    eval_result = evaluator.evaluate(rag_dataset.examples[0].query,response)
  File "/Users/asanthan/work/development/greenfield/demos/generative-ai/RAG/venv/lib/python3.10/site-packages/llama_index/evaluation/base.py", line 62, in evaluate
    return asyncio.run(
  File "/Users/asanthan/work/development/greenfield/demos/generative-ai/RAG/venv/lib/python3.10/site-packages/nest_asyncio.py", line 30, in run
    return loop.run_until_complete(task)
  File "/Users/asanthan/work/development/greenfield/demos/generative-ai/RAG/venv/lib/python3.10/site-packages/nest_asyncio.py", line 98, in run_until_complete
    return f.result()
  File "/Users/asanthan/.pyenv/versions/3.10.10/lib/python3.10/asyncio/futures.py", line 201, in result
    raise self._exception.with_traceback(self._exception_tb)
  File "/Users/asanthan/.pyenv/versions/3.10.10/lib/python3.10/asyncio/tasks.py", line 232, in __step
    result = coro.send(None)
  File "/Users/asanthan/work/development/greenfield/demos/generative-ai/RAG/venv/lib/python3.10/site-packages/llama_index/evaluation/faithfulness.py", line 130, in aevaluate
    raise ValueError("contexts and response must be provided")
ValueError: contexts and response must be provided