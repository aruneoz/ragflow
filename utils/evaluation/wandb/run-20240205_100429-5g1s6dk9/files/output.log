wandb: Streaming LlamaIndex events to W&B at https://wandb.ai/arunk777/gemini-test/runs/5g1s6dk9
wandb: `WandbCallbackHandler` is currently in beta.
wandb: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.
[nltk_data] Downloading package punkt to /Users/asanthan/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /Users/asanthan/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
Parsing nodes: 100%|██████████| 1/1 [00:00<00:00, 28.45it/s]

100%|██████████| 8/8 [00:04<00:00,  1.92it/s]
100%|██████████| 2/2 [00:01<00:00,  1.72it/s]
100%|██████████| 2/2 [00:01<00:00,  1.94it/s]
100%|██████████| 2/2 [00:00<00:00,  2.28it/s]
100%|██████████| 2/2 [00:01<00:00,  1.99it/s]
100%|██████████| 2/2 [00:01<00:00,  1.33it/s]
100%|██████████| 2/2 [00:01<00:00,  1.61it/s]
100%|██████████| 2/2 [00:01<00:00,  1.08it/s]

100%|██████████| 2/2 [00:01<00:00,  1.16it/s]
What is the maximum number of axes that can be supported by a single Power Interface Module (PIM) in the ArmorKinetix system?
Traceback (most recent call last):
  File "/Users/asanthan/work/development/greenfield/demos/generative-ai/RAG/utils/evaluation/rag_evaluation.py", line 123, in <module>
    loop = asyncio.run(batch())
  File "/Users/asanthan/.pyenv/versions/3.10.10/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/Users/asanthan/.pyenv/versions/3.10.10/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/Users/asanthan/work/development/greenfield/demos/generative-ai/RAG/utils/evaluation/rag_evaluation.py", line 105, in batch
    eval_result = evaluator.evaluate(response)
  File "/Users/asanthan/work/development/greenfield/demos/generative-ai/RAG/venv/lib/python3.10/site-packages/llama_index/evaluation/base.py", line 62, in evaluate
    return asyncio.run(
  File "/Users/asanthan/work/development/greenfield/demos/generative-ai/RAG/venv/lib/python3.10/site-packages/nest_asyncio.py", line 30, in run
    return loop.run_until_complete(task)
  File "/Users/asanthan/work/development/greenfield/demos/generative-ai/RAG/venv/lib/python3.10/site-packages/nest_asyncio.py", line 98, in run_until_complete
    return f.result()
  File "/Users/asanthan/.pyenv/versions/3.10.10/lib/python3.10/asyncio/futures.py", line 201, in result
    raise self._exception.with_traceback(self._exception_tb)
  File "/Users/asanthan/.pyenv/versions/3.10.10/lib/python3.10/asyncio/tasks.py", line 232, in __step
    result = coro.send(None)
  File "/Users/asanthan/work/development/greenfield/demos/generative-ai/RAG/venv/lib/python3.10/site-packages/llama_index/evaluation/faithfulness.py", line 130, in aevaluate
    raise ValueError("contexts and response must be provided")
ValueError: contexts and response must be provided